# Виртуальный коуч: оценка повторения движений за коучем.

## Содержание
1. [Описание проекта](https://github.com/drSever/drSever_data_science/tree/main/Portfolio/Project_6#Цели-и-задачи-проекта)
2. [Структура проекта](https://github.com/drSever/drSever_data_science/tree/main/Portfolio/Project_6#Структура-проекта)
3. [Требования к исходному видео](https://github.com/drSever/drSever_data_science/tree/main/Portfolio/Project_6#Запуск-приложения)
4. [Запуск приложения](https://github.com/drSever/drSever_data_science/tree/main/Portfolio/Project_6#Stages-of-the-project)
5. [Этапы работы над проектом](https://github.com/drSever/drSever_data_science/tree/main/Portfolio/Project_6#RЭтапы-работы-над-проектом)

## Цели и задачи проекта

Представляю вашему вниманию проект "виртуального коуча", способного анализировать действия человека на видео с помощью распознавания действия по ключевым точкам, обнаруженным на теле человека.

Данный виртуальный коуч может использоваться для:
- обучение танцам, когда на видео присутствует живой "коуч" и "обучаемый", который повторяет движения за "коучем". Затем после анализа представленного видео нашим виртуальным коучем, будет оценено насколько качественно обучаемый повторяет движение за учителем.
- оценка насколько точно одновременно выполняют движения 2 танцора

## Структура проекта

 - */examples* - 2 примера работы "виртуального коуча" в виде 2-х ноутбуков, в которых подробно показаны этапы проекта, поиск решений возникающих проблем (подробнее внутри)
 - */myproject* - пакет проекта, содержащий следующие модули:
    - *model.py* - получение модели и трансформаций для входящих фреймов (кадров) исходного видео
    - *video_preprocessing.py* - преобразование исходного видеофайла в набор начальных фреймов
    - *frames_preprocesing.py* - обработка начальных фреймов: детектирование 2-х танцоров, выделение ключевых точек, построение скедета, расчет и нанесение метрик
    - *video_output.py* - сборка обработанных фреймов в итоговый видеофайл *.avi*
- */output_data* - в данном случае результат запуска и работы приложения (папка хранит исходные и обработанные фреймы, итоговое видео)
#
- *main.py* - запускающий скрипт
- *video.mp4* - в данном случае пример входящего видео для приложения (результат его обработки - в */output_data*)
#
- *project.yml* - рабочее окружение проекта (Anaconda)
- *requirements.txt* - преобразованные зависимости из *project.yml* для *pip*

## Требования к исходному видео

- на видео должно быть 2 танцора
- желательно, чтобы руки/ноги танцоров не накладывались друг на друга и не выходили за пределы кадра
- фигуры танцоров должны находиться в кадре

**Примечание:** если фигура танцора начинает покидать кадр видео, то это может привести к нарушению обнаружения фигуры сетью и прерывание обработки полученных фреймов из начального видео.

## Запуск приложения

- установите рабочее окружение/зависимости
- отредактируйте (если необходимо) скрипт *main.py*: пути к папкам, название файла видео, цвет метрик на итоговом видео
- в корневой каталог поместите исходный видеофайл с названием *video.mp4* (путь и название можно отредактировать в *main.py*)
- в корневом каталоге выполните `python main.py`
- после выполнения приложения в папке */output_data* (по умолчанию) будут сохранены исходные и обработанные фреймы, итоговый видеофайл

Пример фрейма (кадра) до обработки:    

<image src="output_data/frames/frame_10.jpg" width="600">

Пример фрейма (кадра) после обработки:  

<image src="output_data/frames_output/frame_10.jpg"  width="600">

## Этапы работы над проектом

- выполнение спринтов раздела *Real Life CV-специалиста и работа над дипломом*
- выбор модели *keypointrcnn_resnet50_fpn*, выбор метрик
- составление ноутбука с решением
- оформление работы на GitHub