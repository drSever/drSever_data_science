# drSever Data Science SF
Hello everyone! My name is Aleksandr and I am learning Data Science in Skill Factory.
## Note
I will be grateful for the help and criticism of the projects. And I apologize for my English.

# Project: Clusterisation task. 
# Table of contents
1. [Job description](https://github.com/drSever/drSever_data_science/tree/main/Portfolio/Project_3#Job-description)
2. [Quality metric](https://github.com/drSever/drSever_data_science/tree/main/Portfolio/Project_3#Quality-metric)
3. [Stages of the project](https://github.com/drSever/drSever_data_science/tree/main/Portfolio/Project_3#Stages-of-the-project)
4. [Result](https://github.com/drSever/drSever_data_science/tree/main/Portfolio/Project_3#Result)

## Job description

It is necessary to cluster the customers of an online gift store.

**Business task**: segment existing customers, interpret these segments, and define a strategy for interacting with them.

**Technical task**: to build a model for clustering customers based on their purchasing power, order frequency and the age of the last purchase, to determine the profile of each of the clusters.  

The data can be downloaded [here](https://lms.skillfactory.ru/assets/courseware/v1/468638e49cb9e7d4b4dfdc296c1c778e/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/pj6_data.zip).

## Quality metric

Built a model for clustering customers based on their purchasing power, order frequency and the age of the last purchase, to determine the profile of each of the clusters. 

## Stages of the project

- Perform preprocessing of the data set.
- Conduct an exploratory analysis of the data and identify key patterns.
- Form categories of goods and customers.
- Construct several machine learning models that solve the problem of clustering clients, determine the number of clusters and interpreting them.

## Result

- The raw data was downloaded, processed, cleaned, and the EDA was performed.
- The model was trained and the clients were divided into clusters.
- Additional data processing and analysis was performed, a new model was trained and a new partitioning into clusters of raw data was obtained.
- Project files uploaded to GitHub. 


